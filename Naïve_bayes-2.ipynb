{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dac69da-63b7-4dbc-a918-0160eb9f19e6",
   "metadata": {},
   "source": [
    "# Q1. A company conducted a survey of its employees and found that 70% of the employees use thecompany's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "To calculate the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use conditional probability. The notation for this probability is \\( P(\\text{Smoker}|\\text{Uses Insurance}) \\), and it is calculated using the formula:\r\n",
    "\r\n",
    "\\[ P(\\text{Smoker}|\\text{Uses Insurance}) = \\frac{P(\\text{Smoker} \\cap \\text{Uses Insurance})}{P(\\text{Uses Insurance})} \\]\r\n",
    "\r\n",
    "The information given in the problem is as follows:\r\n",
    "\r\n",
    "- \\( P(\\text{Uses Insurance}) = 0.70 \\) (the probability that an employee uses the health insurance plan).\r\n",
    "- \\( P(\\text{Smoker}|\\text{Uses Insurance}) = 0.40 \\) (the probability that an employee is a smoker given that he/she uses the health insurance plan).\r\n",
    "\r\n",
    "Let's calculate \\( P(\\text{Smoker} \\cap \\text{Uses Insurance}) \\) using the formula:\r\n",
    "\r\n",
    "\\[ P(\\text{Smoker} \\cap \\text{Uses Insurance}) = P(\\text{Smoker}|\\text{Uses Insurance}) \\cdot P(\\text{Uses Insurance}) \\]\r\n",
    "\r\n",
    "Substitute the given values:\r\n",
    "\r\n",
    "\\[ P(\\text{Smoker} \\cap \\text{Uses Insurance}) = 0.40 \\cdot 0.70 \\]\r\n",
    "\r\n",
    "Now, use this result to calculate \\( P(\\text{Smoker}|\\text{Uses Insurance}) \\):\r\n",
    "\r\n",
    "\\[ P(\\text{Smoker}|\\text{Uses Insurance}) = \\frac{0.40 \\cdot 0.70}{0.70} \\]\r\n",
    "\r\n",
    "Simplify the expression:\r\n",
    "\r\n",
    "\\[ P(\\text{Smoker}|\\text{Uses Insurance}) = 0.40 \\]\r\n",
    "\r\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 0.40, or 40%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05119d7e-bb73-4281-897f-5ce560c220b5",
   "metadata": {},
   "source": [
    "# Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "Bernoulli Naive Bayes and Multinomial Naive Bayes are two variants of the Naive Bayes classifier, and they are designed for different types of data. Here are the key differences between the two:\r\n",
    "\r\n",
    "1. **Nature of the Features:**\r\n",
    "   - **Bernoulli Naive Bayes:** It is suitable for binary data, where features represent the presence or absence of a particular attribute. The model assumes that each feature is a binary-valued variable.\r\n",
    "   - **Multinomial Naive Bayes:** It is designed for discrete data, typically used when features represent counts or frequencies. This is commonly used in text classification where features are word counts.\r\n",
    "\r\n",
    "2. **Feature Representation:**\r\n",
    "   - **Bernoulli Naive Bayes:** Features are represented as binary variables (0 or 1), indicating the absence or presence of a feature.\r\n",
    "   - **Multinomial Naive Bayes:** Features are typically represented as integer counts, indicating the number of occurrences of a feature.\r\n",
    "\r\n",
    "3. **Probability Distribution:**\r\n",
    "   - **Bernoulli Naive Bayes:** Assumes a Bernoulli distribution for each feature, modeling the probability of occurrence as a binary outcome.\r\n",
    "   - **Multinomial Naive Bayes:** Assumes a multinomial distribution for each feature, modeling the probability of occurrence as a count-based outcome.\r\n",
    "\r\n",
    "4. **Use Cases:**\r\n",
    "   - **Bernoulli Naive Bayes:** Often used in document classification tasks, especially when the presence or absence of certain words in a document is crucial (e.g., spam detection).\r\n",
    "   - **Multinomial Naive Bayes:** Commonly used in natural language processing tasks, such as document classification or sentiment analysis, where the frequency of words in a document is important.\r\n",
    "\r\n",
    "5. **Application in Scikit-Learn:**\r\n",
    "   - **Bernoulli Naive Bayes:** In scikit-learn, you can use the `BernoulliNB` class.\r\n",
    "   - **Multinomial Naive Bayes:** In scikit-learn, you can use the `MultinomialNB` class.\r\n",
    "\r\n",
    "In summary, the choice between Bernoulli Naive Bayes and Multinomial Naive Bayes depends on the nature of your data. If your features are binary or represent the presence/absence of attributes, use Bernoulli Naive Bayes. If your features are counts or frequencies, especially in the context of text data, use Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f345c8-a5d2-488e-aed7-bc0255de4beb",
   "metadata": {},
   "source": [
    "# Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "In scikit-learn's implementation of Bernoulli Naive Bayes, missing values are treated as if they were absent (0) when calculating probabilities. This is consistent with the assumption of the Bernoulli distribution, where features are binary variables representing the presence or absence of a particular attribute.\n",
    "\n",
    "Here's how scikit-learn's `BernoulliNB` handles missing values:\n",
    "\n",
    "1. **Training Phase:**\n",
    "   - During the training phase, the model estimates probabilities based on the presence or absence of features.\n",
    "   - Missing values are treated as if they were absent (0). The model learns the probabilities of each feature being 0 or 1 in each class.\n",
    "\n",
    "2. **Prediction Phase:**\n",
    "   - When making predictions for new instances with missing values, the model uses the probabilities learned during training.\n",
    "   - The missing values are implicitly treated as if they were absent (0) when computing the likelihood of each feature.\n",
    "\n",
    "It's important to note that the handling of missing values is implicit in the sense that the model doesn't have a specific mechanism for dealing with missing values. The missing values are effectively treated as one of the possible values of the feature, and the model learns how the presence or absence of features correlates with class labels based on the available data.\n",
    "\n",
    "If your dataset has a significant number of missing values, it's a good practice to consider imputation techniques or preprocessing methods to handle missing data before training a machine learning model. Imputation involves filling in missing values with estimated or substituted values, and scikit-learn provides tools such as the `SimpleImputer` class for this purpose. After imputation, you can then proceed to train your Bernoulli Naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a5339-b0ad-4f30-8f2a-ffb7ad995a7d",
   "metadata": {},
   "source": [
    "# Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. The Gaussian Naive Bayes classifier is a variant of the Naive Bayes algorithm that assumes that the features follow a Gaussian (normal) distribution. It is well-suited for continuous data.\n",
    "\n",
    "In the case of multi-class classification, where there are more than two classes, Gaussian Naive Bayes can be extended to handle multiple classes by using the \"one-vs-all\" (OvA) or \"one-vs-one\" (OvO) strategy. Here's a brief explanation of both strategies:\n",
    "\n",
    "1. **One-vs-All (OvA):**\n",
    "   - Also known as \"one-vs-rest,\" this strategy involves training a separate binary classifier for each class. Each classifier is trained to distinguish one class from the rest.\n",
    "   - During prediction, the class with the highest predicted probability among all the binary classifiers is chosen as the final predicted class.\n",
    "\n",
    "2. **One-vs-One (OvO):**\n",
    "   - In this strategy, a binary classifier is trained for every pair of classes. For \\(K\\) classes, this results in \\(K(K-1)/2\\) binary classifiers.\n",
    "   - During prediction, each classifier \"votes\" for one of the classes. The class that receives the most votes is the final predicted class.\n",
    "\n",
    "Scikit-learn, a popular machine learning library in Python, provides a `GaussianNB` class for Gaussian Naive Bayes classification. By default, this class supports multi-class classification using the OvO strategy. You can use it in a straightforward manner, specifying the target classes when fitting the model.\n",
    "\n",
    "Here's a simple example of using Gaussian Naive Bayes for multi-class classification in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810a330f-cf26-45ea-9f19-e665e9a23289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset as an example\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Gaussian Naive Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec88ffb-761d-4da9-8857-bb4753eb788a",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b067ad79-dfb3-4a21-ab9e-93f5a8bd83d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Metrics:\n",
      "Accuracy: 0.8839380364047911\n",
      "\n",
      "Multinomial Naive Bayes Metrics:\n",
      "Accuracy: 0.7863496180326323\n",
      "\n",
      "Gaussian Naive Bayes Metrics:\n",
      "Accuracy: 0.8217730830896915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Spambase dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "columns = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \"word_freq_our\", \n",
    "           \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \"word_freq_order\", \n",
    "           \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \"word_freq_people\", \n",
    "           \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \"word_freq_business\", \n",
    "           \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \"word_freq_your\", \n",
    "           \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \n",
    "           \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \n",
    "           \"word_freq_labs\", \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \n",
    "           \"word_freq_415\", \"word_freq_85\", \"word_freq_technology\", \"word_freq_1999\", \n",
    "           \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\", \"word_freq_cs\", \n",
    "           \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \n",
    "           \"word_freq_re\", \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \n",
    "           \"char_freq_;\", \"char_freq_(\", \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \n",
    "           \"char_freq_#\", \"capital_run_length_average\", \"capital_run_length_longest\", \n",
    "           \"capital_run_length_total\", \"is_spam\"]\n",
    "\n",
    "# Assuming the data is in CSV format and has a header row\n",
    "data = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.iloc[:, :-1]\n",
    "y = data['is_spam']\n",
    "\n",
    "# Initialize classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    return accuracy  # Return a single numeric value\n",
    "\n",
    "# Perform 10-fold cross-validation and calculate metrics for each classifier\n",
    "metrics_bernoulli = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='accuracy')\n",
    "metrics_multinomial = cross_val_score(multinomial_nb, X, y, cv=10, scoring='accuracy')\n",
    "metrics_gaussian = cross_val_score(gaussian_nb, X, y, cv=10, scoring='accuracy')\n",
    "\n",
    "# Display results\n",
    "print(\"Bernoulli Naive Bayes Metrics:\")\n",
    "print(\"Accuracy:\", metrics_bernoulli.mean())\n",
    "print()\n",
    "\n",
    "print(\"Multinomial Naive Bayes Metrics:\")\n",
    "print(\"Accuracy:\", metrics_multinomial.mean())\n",
    "print()\n",
    "\n",
    "print(\"Gaussian Naive Bayes Metrics:\")\n",
    "print(\"Accuracy:\", metrics_gaussian.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60166c-ddeb-4b67-8404-1a29f78ab4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ccd413-a6ed-45d4-ba6b-3c65533c99b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcabb45f-f9fd-409b-ab54-eb2d21bba27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975fb157-7975-4ac3-99c4-b5126518df75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f3906-2b64-4468-b269-a7c580a29193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9efa8-49cc-40fd-a15c-55050bc555ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da9641d-6deb-4431-a958-06a9a83e5384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2eaee4-f88e-4d14-859e-2fc6a01517b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d835e-5786-4b71-ab94-a13a79c77b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa734461-57f9-4bed-85f8-79626cdbcafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23abb81-3141-4ca3-83d1-e414dde2b7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2c017-996b-49f2-9f8b-f62096f34335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c602935-a734-494d-8fa7-9814b5fc8c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdf544b-2144-42e6-a18d-42a02c449770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffdb44d-a014-4c4d-91d4-8a49a339f89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfa7f3-ec50-4ccb-8ad8-16a61b5df23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f101a88e-090f-4f29-abd3-d2c93fcf7a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffae636-c1b6-4f60-a9b8-0c641ea183d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e7e53-560e-4175-8056-ed2e14137058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ca1279-7131-4df8-b6a5-18d16e968598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c61ec-65ee-4f8b-b528-e43daa68edd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18632b10-ca28-4f68-bc7b-ece258a11736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba4de4-a6a0-4cc7-a45c-0a8c81048642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf27b21-3b15-4606-8828-12305edff955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edad061-eacf-417c-96f9-c45d9aac0ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5401ba40-7225-4a42-ad15-da2fc0b11e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9333fded-ece2-494a-98b4-6b8282e07267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6d903-6b5b-4aa5-b301-efa42996af9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6422d8-39c5-4701-a040-2fcd4c8a53c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d803045-24c4-467c-919b-d51cd242cd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea8b35-ffb0-449a-9bfe-86a9c4221c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c2c29-9512-47ce-8c56-3bec2a1b34b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f92e0-57db-4c76-ba06-1c04efcfaf38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942288c4-00c0-43fd-bb5a-a7d69b6e30c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
